{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdab47a-2a0f-4e9b-b3d4-e542a793f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=100, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=100, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=100, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=100, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=100, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=10, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=10, min_samples_split=2, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=10, min_samples_split=2, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=10, min_samples_split=2, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=10, min_samples_split=2, n_estimators=700; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=800; total time=   0.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=800; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=800; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=800; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=100, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=100, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=100, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=100, n_estimators=500; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=100, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=10, n_estimators=900; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=10, min_samples_split=10, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=10, min_samples_split=10, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=10, min_samples_split=10, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=10, min_samples_split=10, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=10, min_samples_split=10, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=100, n_estimators=700; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=100, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=100, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=100, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=100, n_estimators=700; total time=   0.7s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1100; total time=   1.8s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1100; total time=   1.3s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1100; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srsha\\anaconda3\\envs\\carprediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "5 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\srsha\\anaconda3\\envs\\carprediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\srsha\\anaconda3\\envs\\carprediction\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\srsha\\anaconda3\\envs\\carprediction\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\srsha\\anaconda3\\envs\\carprediction\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\srsha\\anaconda3\\envs\\carprediction\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [ -5.23524801 -11.31547759  -9.1810102   -6.89775321  -8.42088393\n",
      "          nan  -7.26907862  -9.15125338 -11.30424218  -5.57340633]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7947042579286103\n",
      "Mean Squared Error: 1.6910783352652745\n",
      "Root Mean Squared Error: 1.3004146781951034\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"car data.csv\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "final_dataset = df[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n",
    "                    'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]\n",
    "final_dataset['Current_Year'] = 2023\n",
    "final_dataset['number_of_years'] = final_dataset['Current_Year'] - final_dataset['Year']\n",
    "final_dataset.drop(['Year', 'Current_Year'], axis=1, inplace=True)\n",
    "final_dataset = pd.get_dummies(final_dataset, drop_first=True)\n",
    "\n",
    "# Split the dataset into independent and dependent features\n",
    "X = final_dataset.iloc[:, 1:]\n",
    "y = final_dataset.iloc[:, 0]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the random grid for hyperparameter tuning\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num=6)]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "# Create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters using 5-fold cross-validation\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                               scoring='neg_mean_squared_error', n_iter=10,\n",
    "                               cv=5, verbose=2, random_state=42, n_jobs=1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = rf_random.best_params_\n",
    "\n",
    "# Create the final Random Forest model with the best hyperparameters\n",
    "rf_final = RandomForestRegressor(n_estimators=best_params['n_estimators'],\n",
    "                                 max_features=best_params['max_features'],\n",
    "                                 max_depth=best_params['max_depth'],\n",
    "                                 min_samples_split=best_params['min_samples_split'],\n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                 random_state=42)\n",
    "\n",
    "# Train the final model on the training data\n",
    "rf_final.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_final.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mae = metrics.mean_absolute_error(y_test, predictions)\n",
    "mse = metrics.mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Save the final model to a file\n",
    "with open('random_forest_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_final, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770de60-34d3-46a4-a77f-bf2cf9897d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
